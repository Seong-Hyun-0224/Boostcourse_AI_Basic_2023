{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "befd5124",
   "metadata": {},
   "source": [
    "# Lab 01-1 Tensor Manipulation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96b598b",
   "metadata": {},
   "source": [
    "### 1D Array with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bdb8cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92113d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "t = np.array([0., 1., 2., 3., 4., 5., 6.])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d07ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of t:  1\n",
      "Shape of t:  (7,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Rank of t: \", t.ndim)\n",
    "print(\"Shape of t: \", t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf4a484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t[0] t[1] t[-1] =  0.0 1.0 6.0\n",
      "t[2:5] t[4:-1] =  [2. 3. 4.] [4. 5.]\n",
      "t[:2] t[3:] =  [0. 1.] [3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "print(\"t[0] t[1] t[-1] = \", t[0], t[1], t[-1]) #Element\n",
    "print('t[2:5] t[4:-1] = ', t[2:5], t[4:-1]) # Slicing\n",
    "print(\"t[:2] t[3:] = \", t[:2], t[3:]) # Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a721d46",
   "metadata": {},
   "source": [
    "## 2D Array with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d111505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]\n",
      " [ 7.  8.  9.]\n",
      " [10. 11. 12.]]\n"
     ]
    }
   ],
   "source": [
    "t = np.array([[1.,2.,3.], [4.,5.,6.], [7.,8.,9.], [10.,11.,12.]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "114f0ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of t:  2\n",
      "Shape of t:  (4, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Rank of t: ', t.ndim)\n",
    "print('Shape of t: ', t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf4279",
   "metadata": {},
   "source": [
    "## 1D Array with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f53f108e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a6f6c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([7])\n",
      "torch.Size([7])\n",
      "tensor(0.) tensor(1.) tensor(6.)\n",
      "tensor([2., 3., 4.]) tensor([4., 5.])\n",
      "tensor([0., 1.]) tensor([3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "print(t.dim()) # rank\n",
    "print(t.shape) # shape\n",
    "print(t.size()) # shape ==>> shape함수나 size함수나 똑같은 값이 나온다.\n",
    "print(t[0], t[1], t[-1])   # Element\n",
    "print(t[2:5], t[4:-1])     # Slicing\n",
    "print(t[:2], t[3:])        # Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd67696",
   "metadata": {},
   "source": [
    "## 2D Array with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4362c9a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1.,2.,3.],\n",
    "                       [4.,5.,6.],\n",
    "                       [7.,8.,9.],\n",
    "                       [10.,11.,12.]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77cb1c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([4, 3])\n",
      "tensor([ 2.,  5.,  8., 11.])\n",
      "torch.Size([4])\n",
      "tensor([[ 1.,  2.],\n",
      "        [ 4.,  5.],\n",
      "        [ 7.,  8.],\n",
      "        [10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "print(t.dim()) # rank\n",
    "print(t.size()) # shape\n",
    "print(t[:, 1])\n",
    "print(t[:, 1].size())\n",
    "print(t[:, :-1]) # 첫번째 차원은 다 가져오고, 맨마지막 차원빼고 다 가져와!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b99a2e7",
   "metadata": {},
   "source": [
    "## Pytorch는 어떻게 다루는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bf0e65",
   "metadata": {},
   "source": [
    "### 첫번째 기능 : Broadcasting - 연산 시 자동적으로 size(shape)을 맞춰준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25d4089a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "# Same shape\n",
    "m1 = torch.FloatTensor([[3, 3]]) # lm1l = (1,2)\n",
    "m2 = torch.FloatTensor([[2, 2]]) # lm1l = lm2l\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "856f4b75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "# Vector + scalar\n",
    "m1 = torch.FloatTensor([[1, 2]]) # lm1l = (1,2)\n",
    "m2 = torch.FloatTensor([3]) # 3 -> [[3, 3]]으로 broadcasting\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f2b6765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# 2 x 1 Vector + 1 x 2 Vector\n",
    "m1 = torch.FloatTensor([[1, 2]]) # lm1l = (1,2)\n",
    "m2 = torch.FloatTensor([[3], [4]]) # lm2l = (2,1)\n",
    "print(m1 + m2) # 원래는 m1, m2의 shape이 달라 덧셈은 안되지만, broadcasting되서 m1도 2x2, m2도 2x2로 변하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffb1cb5",
   "metadata": {},
   "source": [
    "- broadcasting 사용 시에는 어디서 에러가 있는지, 잘못입력되었는지 알 수 없이 정상적으로 연산이 종료되기 때문에 사용 시 유의해야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9887bc9c",
   "metadata": {},
   "source": [
    "## Multiplication vs Matrix Multiplication\n",
    "- 곱셈(원소)\n",
    "- 행렬곱\n",
    "- 딥러닝은 행렬곱을 굉장히 많이 사용하는 알고리즘이 많다.\n",
    "- 그렇기에 잘 이해하고 구현하는 것이 중요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f4e1ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------\n",
      "Mul vss Matmul\n",
      "---------------\n",
      "Shape of Matrix 1 :  torch.Size([2, 2])\n",
      "Shape of Matrix 2 :  torch.Size([2, 1])\n",
      "tensor([[ 5.],\n",
      "        [11.]])\n",
      "Shape of Matrix 1 :  torch.Size([2, 2])\n",
      "Shape of Matrix 2 :  torch.Size([2, 1])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print('---------------')\n",
    "print('Mul vss Matmul')\n",
    "print('---------------')\n",
    "m1 = torch.FloatTensor([[1,2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[1], [2]])\n",
    "print('Shape of Matrix 1 : ', m1.shape)\n",
    "print('Shape of Matrix 2 : ', m2.shape)\n",
    "print(m1.matmul(m2)) # 2 x 1\n",
    "\n",
    "m1 = torch.FloatTensor([[1,2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[1], [2]])\n",
    "print('Shape of Matrix 1 : ', m1.shape)\n",
    "print('Shape of Matrix 2 : ', m2.shape)\n",
    "print(m1 * m2) # 2 x 2\n",
    "print(m1.mul(m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fef97ac",
   "metadata": {},
   "source": [
    "## Mean\n",
    "- 평균\n",
    "- int형에는 쓸 수 없다.\n",
    "- 기본적으로는 FloatTensor를 이용해 Float type의 Tensor를 선언하기에 이것만 유의해주면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d86819ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000)\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([1, 2])\n",
    "print(t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12c84d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long\n"
     ]
    }
   ],
   "source": [
    "# Can't use mean()) on integers\n",
    "t = torch.LongTensor([1, 2])\n",
    "try:\n",
    "    print(t.mean())\n",
    "except Exception as exc:\n",
    "    print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93ebce96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44ab4bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "print(t.mean())\n",
    "print(t.mean(dim=0))\n",
    "print(t.mean(dim=1))\n",
    "print(t.mean(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75da1ea5",
   "metadata": {},
   "source": [
    "## Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "917a74ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a6abbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.)\n",
      "tensor([4., 6.])\n",
      "tensor([3., 7.])\n",
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "source": [
    "print(t.sum())\n",
    "print(t.sum(dim=0))\n",
    "print(t.sum(dim=1))\n",
    "print(t.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de72e6f",
   "metadata": {},
   "source": [
    "## Max and Argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b1389ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "710f91b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "print(t.max()) # Return one value : max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a425c8f",
   "metadata": {},
   "source": [
    "- The max operator in pytorch returns 2 values when called with dimension specified.\n",
    "- The first value is the maximum value, and the second value is the argmax: the index of the element with maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "064e8196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([3., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "Max:  tensor([3., 4.])\n",
      "Argmax:  tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(t.max(dim=0)) # Returns two values: max and argmax\n",
    "print('Max: ', t.max(dim=0)[0])\n",
    "print('Argmax: ', t.max(dim=0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a04811c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n"
     ]
    }
   ],
   "source": [
    "print(t.max(dim=1))\n",
    "print(t.max(dim=-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
